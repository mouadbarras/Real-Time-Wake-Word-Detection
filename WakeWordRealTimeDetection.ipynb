{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a60d5b0-d24d-4c88-b5ca-6ccdabd1039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import queue\n",
    "import numpy as np\n",
    "import librosa\n",
    "import sys\n",
    "import tensorflow as tf  # Use TensorFlow for TFLite support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4445e270-2ff0-4775-b7a1-514dae678274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "fs = 44100  # Sampling rate (44 kHz is standard for speech processing)\n",
    "sc = 0.7    # Chunk duration in seconds\n",
    "silence_threshold = 0.001  # Threshold for RMS to detect silence\n",
    "chunk_size = int(fs * sc)  # Number of samples per chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca21a90-08b9-44d3-b54b-6bd0ae084e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queue for audio chunks\n",
    "audio_queue = queue.Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "599fe746-850b-400f-a5ff-ffb083febd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite model using TensorFlow\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/HP/Desktop/WakeWordDetection/models/WWD.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa09a2da-5a17-4616-9486-3625205feb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function: Compute RMS (Root Mean Square) to detect silence\n",
    "def compute_rms(audio_chunk):\n",
    "    return np.sqrt(np.mean(audio_chunk**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4dd3df3-af8b-4231-b41b-90b08e3b11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio callback: Capture audio in real-time\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    if status:\n",
    "        print(f\"Stream status: {status}\")\n",
    "    audio_queue.put(indata.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b99f8a-dbb7-43ec-9dba-49c9d1399ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing function\n",
    "def process_audio():\n",
    "    while True:\n",
    "        if not audio_queue.empty():\n",
    "            # Get audio chunk from the queue\n",
    "            buffer = audio_queue.get()\n",
    "\n",
    "            # Ensure buffer length matches chunk size\n",
    "            if len(buffer) < chunk_size:\n",
    "                continue  # Skip if the buffer is incomplete\n",
    "\n",
    "            # Compute RMS to detect silence\n",
    "            rms = compute_rms(buffer)\n",
    "            #print(f\"RMS: {rms}\")  # Debugging output for RMS\n",
    "\n",
    "            if rms < silence_threshold:\n",
    "                sys.stdout.write('-')  # Indicate silence\n",
    "                continue  # Skip further processing for silence\n",
    "\n",
    "            # Extract MFCC features\n",
    "            mfcc = librosa.feature.mfcc(y=buffer.flatten(), sr=fs, n_mfcc=40)\n",
    "            mfcc_processed = np.mean(mfcc.T, axis=0)  # Averaging over time steps\n",
    "            mfcc_processed = mfcc_processed.reshape(40, 1)  # Reshape to (32, 1)\n",
    "\n",
    "            # Pad or resize to match the model input shape (32, 32)\n",
    "            mfcc_processed = np.pad(mfcc_processed, ((0, max(0, 32 - mfcc_processed.shape[0])), (0, 31)), 'constant')\n",
    "            mfcc_processed = mfcc_processed[:32]  # Ensure exactly 32 rows\n",
    "            mfcc_processed = np.expand_dims(mfcc_processed, axis=0)  # Add batch dimension\n",
    "            mfcc_processed = np.expand_dims(mfcc_processed, axis=-1)  # Add channel dimension\n",
    "\n",
    "            # Print MFCC shape for debugging\n",
    "            #print(f\"MFCC shape: {mfcc_processed.shape}\")  \n",
    "\n",
    "            # Run inference with TFLite model\n",
    "            interpreter.set_tensor(input_details[0]['index'], mfcc_processed.astype(np.float32))\n",
    "            interpreter.invoke()\n",
    "\n",
    "            # Get prediction results\n",
    "            prediction = interpreter.get_tensor(output_details[0]['index'])\n",
    "            #print(f\"Prediction scores: {prediction}\")  # Debugging output for predictions\n",
    "\n",
    "            # Check prediction confidence\n",
    "            if prediction[0, 1] > 0.8:  # Lower threshold for testing\n",
    "                #print(\"Wake word detected!\")  # Wake Word Detected\n",
    "                sys.stdout.write('1')\n",
    "            else:\n",
    "                #print(\"No wake word.\")  # Wake Word NOT Detected\n",
    "                sys.stdout.write('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a01132-2952-4700-a886-baf99307655f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for the wake word... Press Ctrl+C to stop.\n",
      "-................1..--....1..-....--.-..1.........1.....1...1--...11.1-.--.-.1-."
     ]
    }
   ],
   "source": [
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Listening for the wake word... Press Ctrl+C to stop.\")\n",
    "    try:\n",
    "        # Open the audio stream\n",
    "        with sd.InputStream(\n",
    "            callback=audio_callback,\n",
    "            channels=1,\n",
    "            samplerate=fs,\n",
    "            dtype='float32',\n",
    "            blocksize=chunk_size\n",
    "        ):\n",
    "            process_audio()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nStopping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
