{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab8a092-0637-47af-8b5a-822144ac2f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from scipy.io.wavfile import write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a1fa2da-cda4-4ba6-84dd-8b73fb92ac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "fs = 44100  # Sampling frequency (Hz)\n",
    "sc = 1  # Time for each chunk in seconds\n",
    "silence_threshold = 0.002 # change this as you like  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb66a1d-a3ef-4f29-81b6-e979faffecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model\n",
    "tflite_model_path = \"C:/Users/HP/Desktop/WakeWordDetection/models/WWD.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf8e03e5-3ad6-4078-9c06-83bfa098c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6c7207b-96f8-4ae8-a3c3-4790f3739635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffer for continuous audio data\n",
    "buffer = np.zeros((0,))\n",
    "\n",
    "def audio_callback(indata, frames, time, status):\n",
    "    \"\"\"Audio callback function for continuous data recording.\"\"\"\n",
    "    global buffer\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    buffer = np.append(buffer, indata)  # Append new audio to the buffer; hadi bhal dak blan dial segment by segment every 2 seconds but continous in real time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23f6f195-af64-461a-aea5-5978104c5a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rms(audio_data):\n",
    "    \"\"\"Compute the RMS (Root Mean Square) energy of the audio signal.\"\"\"\n",
    "    return np.sqrt(np.mean(np.square(audio_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc236c-5b64-42eb-b53c-382cc232c38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak Now: \n",
      "Recording... Press i deux fois to stop.\n",
      "--........-.-.-.-............1........-..--.........-...........-.-...-...-.-..............-.-.-..........-.-.-.-.-.-..........-.....-.-.1......-.-..--.--....--..-..-.....-.-........-...-.-.......-....-.-...-.-.......-.-...."
     ]
    }
   ],
   "source": [
    "print(\"Speak Now: \")\n",
    "\n",
    "# Open the audio stream\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=fs, dtype='float32'):\n",
    "    print(\"Recording... Press i deux fois to stop.\")\n",
    "    try:\n",
    "        while True:\n",
    "            if len(buffer) > fs * sc:  # Process audio when buffer reaches 1 second\n",
    "                # Extract 1-second chunk from the buffer\n",
    "                audio_chunk = buffer[:fs * sc]\n",
    "                buffer = buffer[fs * sc:]  # Update buffer with the remaining data\n",
    "\n",
    "                # Compute RMS to detect silence\n",
    "                rms = compute_rms(audio_chunk)\n",
    "                if rms < silence_threshold:\n",
    "                    sys.stdout.write('-')  # Indicate silence\n",
    "                    continue  # Skip further processing for silence\n",
    "\n",
    "                # Load and process the audio\n",
    "                mfcc = librosa.feature.mfcc(y=audio_chunk, sr=fs, n_mfcc=32)\n",
    "                mfcc_processed = np.mean(mfcc.T, axis=0)  # Averaging over time steps\n",
    "                mfcc_processed = mfcc_processed.reshape(32, 1)  # Reshape to (32, 1)\n",
    "\n",
    "                # Pad or resize to match the model input shape (32, 32)\n",
    "                mfcc_processed = np.pad(mfcc_processed, ((0, max(0, 32 - mfcc_processed.shape[0])), (0, 31)), 'constant')\n",
    "                mfcc_processed = mfcc_processed[:32]  # Ensure exactly 32 rows\n",
    "                mfcc_processed = np.expand_dims(mfcc_processed, axis=0)  # Add batch dimension\n",
    "                mfcc_processed = np.expand_dims(mfcc_processed, axis=-1)  # Add channel dimension\n",
    "\n",
    "                # Run inference with TFLite model\n",
    "                interpreter.set_tensor(input_details[0]['index'], mfcc_processed.astype(np.float32))\n",
    "                interpreter.invoke()\n",
    "\n",
    "                # Get prediction results\n",
    "                prediction = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "                # Check prediction confidence\n",
    "                if prediction[0, 1] > 0.99:  # Assuming class 1 is \"Wake Word Detected\"\n",
    "                    sys.stdout.write('1')  # Wake Word Detected\n",
    "                else:\n",
    "                    sys.stdout.write('.')  # Wake Word NOT Detected\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nDetection stopped by user.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17a99f-73d4-48eb-aa91-fa91e9aec586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
